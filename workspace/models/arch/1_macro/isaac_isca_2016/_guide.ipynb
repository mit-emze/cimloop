{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_tests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scripts\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhelper_functions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m display_markdown(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mThis is a digital architecture based on the paper \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA 95.6-TOPS/W Deep Learning Inference\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m display_diagram(get_diagram(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscc_proj_2025\u001b[39m\u001b[38;5;124m\"\u001b[39m, ignore\u001b[38;5;241m=\u001b[39mDIAGRAM_DEFAULT_IGNORE))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper_functions'"
     ]
    }
   ],
   "source": [
    "from _tests import scripts\n",
    "from scripts.notebook_utils import *\n",
    "\n",
    "display_markdown(f\"\"\"\n",
    "# Model of \"ISAAC: A Convolutional Neural Network Accelerator with In-Situ\n",
    "Analog Arithmetic in Crossbars!\", ISAC 2016\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Paper by Ali Shafiee, Anirban Nag, Naveen Muralimanohar, Rajeev Balasubramonian,\n",
    "John Paul Strachan, Miao Hu, R. Stanley Williams, and Vivek Srikumar.\n",
    "\n",
    "ISAAC is a ReRAM-based analog CiM accelerator. It explores several concepts in\n",
    "CiM acceleration, including storing different layers in different arrays and\n",
    "pipelining inputs/outputs between.\n",
    "\n",
    "{get_important_variables_markdown('isaac_isca_2016')}\n",
    "\n",
    "### Tile Level\n",
    "\n",
    "Twelve macros (called IMAs in the paper) are organized into a tile. Each tile\n",
    "includes a 64kB eDRAM buffer storing 16b inputs/outputs and quantization\n",
    "circuits. The original paper included sigmoid units at this level, but we\n",
    "replaced them with quantization circuits to match the other works. ISAAC uses\n",
    "16b fixed-point quantization for all operands.\n",
    "\n",
    "- *Input Path*: Inputs are stored in the eDRAM. An inter-macro network sends\n",
    "  inputs to macros in the tile.\n",
    "- *Weight Path*: Weights are kept static in inference and do not move through\n",
    "  this level.\n",
    "- *Output Path*: Outputs are gathered from macros via the inter-tile network.\n",
    "  They are quantized before being stored in the eDRAM.\n",
    "\n",
    "Next, there are 12 macros in each tile. Inputs and outputs are unicast between\n",
    "macros.\n",
    "\n",
    "### Macro Level\n",
    "\n",
    "Eight arrays are organized into a macro with an input register and output\n",
    "register. An input network sends input vectors to arrays.\n",
    "\n",
    "The eight arrays can process up to 8×128 = 1024 inputs across all rows, so the\n",
    "input register is sized 2kB (2B per input). The output register is sized 256B\n",
    "(2B per output, 128 outputs total (8 arrays × 128 columns × 2b per column / 16b\n",
    "per output)). While the paper does not do this, we double output buffer size to\n",
    "account for higher-precision accumulation that is important for lower-precision\n",
    "quantization.\n",
    "\n",
    "- *Input Path*: Inputs are stored in the input buffer and multicast between\n",
    "  arrays.\n",
    "- *Weight Path*: Weights are kept static in inference and do not move through\n",
    "  this level.\n",
    "- *Output Path*: Outputs are stored in the output buffer and spatially reduced\n",
    "  between arrays. Before the output buffer, a shift+add circuit accumulates\n",
    "  outputs and corrects for offsets caused by slicing.\n",
    "\n",
    "Next, there are 8 arrays in each macro. Inputs and outputs can be spatially\n",
    "reused across arrays with a multicast/reduction network.\n",
    "\n",
    "### Array Level\n",
    "\n",
    "Arrays consist of 128 × 128 ReRAMs. Each array is programmed with weights from\n",
    "one DNN layer, and each weight filter uses 8 array columns (16b weights, 2b per\n",
    "column). 1-bit DACs encode inputs across 16 cycles and 8-bit ADCs convert\n",
    "outputs from each column.\n",
    "\n",
    "We note that the original ISAAC paper included a contribution to decrease\n",
    "required ADC precision. Instead of supporting between 0 and the maximum output\n",
    "of a column, ISAAC supported only half of the range. They ensured that all\n",
    "column outputs would be in this range at program time. If the average weight\n",
    "slice value in a column was less than half of the maximum output, the column\n",
    "could not saturate the ADC. If the average weight slice value was greater than\n",
    "half of the maximum output, ISAAC would store the negated value of the weights.\n",
    "To correct for this, ISAAC would need to record sums of the input values, record\n",
    "which weight columns were negated, and perform arithmetic to recover the real\n",
    "sums from the negated sums.\n",
    "\n",
    "When we modeled ISAAC's accuracy, we found that this technique was not helpful\n",
    "across any tested workloads because weights tended to have about half of the\n",
    "maximum value and input bits tended to have >50% sparsity, so on average output\n",
    "of a column was around 25% of the output range anyway and never exceeded 50%. We\n",
    "can therefore just use the lower half of the ADC range to achieve the same\n",
    "result (lower ADC precision) without any of the additional complexity introduced\n",
    "by this strategy. For this reason, we don't model this technique in our ISAAC\n",
    "model.\n",
    "\n",
    "Inputs and weights are both assumed to be 16b unsigned fixed-point numbers.\n",
    "Signed inputs and weights are converted by adding a bias to the inputs and\n",
    "weights.\n",
    "\n",
    "- *Input Path*: Inputs pass through a 1-bit DACs and appear on the rows of the\n",
    "  array.\n",
    "- *Weight Path*: Weights are stored in the array and are not moved during\n",
    "  inference.\n",
    "- *Output Path*: Outputs are read from the columns of the array with 8-bit ADCs.\n",
    "\n",
    "Next, there are 128 columns in each array. Inputs are reused between columns\n",
    "(*i.e.,* each input-carrying wire connects to all columns), while outputs and\n",
    "weights are not reused.\n",
    "\n",
    "### Column Level\n",
    "\n",
    "Each column consists of 128 ReRAM devices. Columns store 2b weight slices.\n",
    "\n",
    "- *Input Path*: Each input is passed directly to a row in the column.\n",
    "- *Weight Path*: Weights are not moved during inference.\n",
    "- *Output Path*: Outputs pass through a current mirror to buffer their values\n",
    "  before exiting the column.\n",
    "  \n",
    "### Row Level\n",
    "\n",
    "Each row in a column has one ReRAM device which stores an offset-encoded 2b\n",
    "weight slice.\n",
    "\n",
    "- *Input Path*: The input is used for a MAC operation.\n",
    "- *Weight Path*: A 2b weight is stored in the ReRAM device and is used for a MAC\n",
    "  operation.\n",
    "- *Output Path*: The output is supplied by a MAC operation.\n",
    "\n",
    "                 \n",
    "\"\"\")\n",
    "display_diagram(get_diagram(\"isaac_isca_2016\", ignore=DIAGRAM_DEFAULT_IGNORE, tile=\"isaac\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "   This test explores the energy, area, and latency of the accelerator\n",
       "   computing MVM operations. We note a few differences from the original ISAAC\n",
       "   paper. Notably, we made a few changes to the quantization, and we use\n",
       "   data-value-dependent models while ISAAC used a simple fixed-power model.\n",
       "   \n",
       "   We note:\n",
       "   - Energy is dominated by the ADC and memory cells due to the high ADC precision\n",
       "     and large number of slices.\n",
       "   - Area is dominated by ADC.\n",
       "   "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CIM_ARCHITECTURE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/workspace/scripts/utils.py\", line 151, in quick_run\n    return run_mapper(spec, accelergy_verbose=accelergy_verbose)\n  File \"/home/workspace/scripts/utils.py\", line 118, in run_mapper\n    mapper_result = tl.call_mapper(\n  File \"/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/backend_calls.py\", line 218, in call_mapper\n    input_paths, output_dir = _pre_call(\n  File \"/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/backend_calls.py\", line 81, in _pre_call\n    input_content = _specification_to_yaml_string(specification, for_model)\n  File \"/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/backend_calls.py\", line 46, in _specification_to_yaml_string\n    specification = specification._process()\n  File \"/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/base_specification.py\", line 215, in _process\n    spec.parse_expressions()\n  File \"/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/v4/specification.py\", line 90, in parse_expressions\n    class2obj(p).pre_parse_process(self)\n  File \"/home/workspace/scripts/processors.py\", line 127, in pre_parse_process\n    if not spec.variables[\"CIM_ARCHITECTURE\"]:\n  File \"/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/nodes.py\", line 1385, in __getitem__\n    return super().__getitem__(__key)\n  File \"/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/nodes.py\", line 1049, in __getitem__\n    return super().__getitem__(key)  # type: ignore\nKeyError: 'CIM_ARCHITECTURE'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43misaac_isca_2016\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_energy_breakdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m n_subplots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(result)\n\u001b[1;32m      3\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/scripts/notebook_utils.py:143\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(macro_name, test_name, show_doc, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([line[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[1;32m    142\u001b[0m     display_markdown(doc)\n\u001b[0;32m--> 143\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mtest_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m clean_old_output_files()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/models/arch/1_macro/isaac_isca_2016/_tests.py:25\u001b[0m, in \u001b[0;36mtest_energy_breakdown\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_energy_breakdown\u001b[39m():\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    This test explores the energy, area, and latency of the accelerator\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    computing MVM operations. We note a few differences from the original ISAAC\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    - Area is dominated by ADC.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mutl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mutl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquick_run\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmacro\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMACRO_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43misaac\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlarge_router\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     results\u001b[38;5;241m.\u001b[39mclear_zero_areas()\n\u001b[1;32m     33\u001b[0m     results\u001b[38;5;241m.\u001b[39mclear_zero_energies()\n",
      "File \u001b[0;32m~/scripts/utils.py:36\u001b[0m, in \u001b[0;36mparallel_test\u001b[0;34m(delayed_calls, n_jobs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     delayed_calls \u001b[38;5;241m=\u001b[39m [delayed_calls]\n\u001b[1;32m     35\u001b[0m delayed_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(delayed_calls)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMacroOutputStatsList\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_as\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdelayed_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scripts/tl_output_parsing.py:109\u001b[0m, in \u001b[0;36mMacroOutputStatsList.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/v4/output_parsing.py:350\u001b[0m, in \u001b[0;36mOutputStatsList.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CIM_ARCHITECTURE'"
     ]
    }
   ],
   "source": [
    "result = run_test(\"isaac_isca_2016\", \"test_energy_breakdown\")\n",
    "n_subplots = len(result)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "bar_stacked(\n",
    "    {f\"\": r.per_compute('per_component_energy')*1e15 for r in result},\n",
    "    ylabel=\"Energy (fJ/MAC)\",\n",
    "    title=f\"Energy Breakdown\",\n",
    "    ax=axs[0]\n",
    ")\n",
    "bar_stacked(\n",
    "    {f\"\" : r.per_component_area*1e12 for r in result},\n",
    "    ylabel=\"Area (um^2)\",\n",
    "    title=f\"Area Breakdown\",\n",
    "    ax=axs[1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "   This test explores the energy, area, and latency of the accelerator when\n",
       "   running full DNN workloads.\n",
       "   "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:09<00:00,  2.19it/s]\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# This test may take a while to run. We have to find a mapping for every layer\n",
    "# for every DNN being tested.\n",
    "results = {}\n",
    "for i, dnn in enumerate([\"resnet18\", \"mobilenet_v3\", \"gpt2_medium\"]):\n",
    "    results[dnn] = run_test(\n",
    "        \"isaac_isca_2016\", \"test_full_dnn\", dnn_name=dnn, show_doc=i == 0\n",
    "    )\n",
    "\n",
    "# Full-DNN results\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "\n",
    "consolidated = {f'{dnn}': result.aggregate() for dnn, result in results.items() }\n",
    "bar_stacked( # Per-MAC Energy\n",
    "    {k: r.per_compute('per_component_energy')*1e15 for k, r in consolidated.items()},\n",
    "    xlabel=\"DNN\",\n",
    "    ylabel=\"Energy (fJ/MAC)\",\n",
    "    title=\"Per-MAC Energy\",\n",
    "    ax=axs[0],\n",
    ")\n",
    "bar_stacked( # Total Energy\n",
    "    {k: r.per_component_energy*1e3 for k, r in consolidated.items()},\n",
    "    xlabel=\"DNN\",\n",
    "    ylabel=\"Energy (mJ)\",\n",
    "    title=\"Total Energy\",\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "tops, tops_per_w = {}, {}\n",
    "for dnn, r in results.items():\n",
    "    agg = r.aggregate()\n",
    "    tops[dnn] = {\"\": agg.tops}\n",
    "    tops_per_w[dnn] = {\"\": agg.tops_per_w}\n",
    "\n",
    "for ax, data, title, ylabel in [\n",
    "    (axs[2], tops, \"Throughput\", \"TOPS\"),\n",
    "    (axs[3], tops_per_w, \"Energy Efficiency\", \"TOPS/W\"),\n",
    "]:\n",
    "    bar_side_by_side(\n",
    "        tops,\n",
    "        xlabel=\"DNN\",\n",
    "        ylabel=f\"{title} ({ylabel})\",\n",
    "        title=f\"Full-DNN {title}\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "# Per-Layer Results\n",
    "for dnn, result in results.items():\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    bar_stacked(\n",
    "        {i: r.per_compute('per_component_energy')*1e15 for i, r in enumerate(result)},\n",
    "        xlabel=\"Layer\",\n",
    "        ylabel=\"Energy (fJ/MAC)\",\n",
    "        title=f\"{dnn} Per-Layer Energy\",\n",
    "        ax=ax[0],\n",
    "    )\n",
    "    for ax, attrname, title, ylabel, scaleby in [\n",
    "        (ax[1], \"latency\", \"Latency\", \"us\", 1e6),\n",
    "        (ax[2], \"energy\", \"Total Energy\", \"mJ\", 1e9),\n",
    "    ]:\n",
    "        bar_side_by_side(\n",
    "            {i: {\"\": getattr(r, attrname) * scaleby} for i, r in enumerate(result)},\n",
    "            xlabel=\"Layer\",\n",
    "            ylabel=f\"{title} ({ylabel})\",\n",
    "            title=f\"{dnn} Per-Layer {title}\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
