{{include_text('../problem_base.yaml')}}
problem:
  <<<: *problem_base
  instance: {M: 139, C: 139, P: 4}

  name: MobileBertSelfAttention
  dnn_name: mobilebert
  notes: From einsum
  # These histograms symmetric and zero-centered (the centermost bin is the
  # probability of zero). Histograms are normalized to sum to 1.0 and they have
  # 2^N-1 bins for some integer N. Higher N yields higher-fidelity histograms,
  # but also increases runtime & the size of YAML files. Encoding functions will
  # upsample or downsample histograms depending on the bitwidth of the
  # corresponding operands.
  histograms:
    Inputs:  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.449,0.13,0.179,0.136,0.0534,0.0219,0.0101,0.00477,0.00294,0.00188,0.00131,0.0012,0.000967,0.000941,0.000588,0.000667,0.000523,0.000457,0.000405,0.000418,0.000575,0.000431,0.000444,0.000261,0.000248,0.000274,0.000353,0.000366,0.000196,0.000118,0.000288,0.000222]
    Weights: [0.0016,0.00143,0.00206,0.00263,0.0036,0.00349,0.004,0.00395,0.00515,0.00578,0.00578,0.00784,0.00927,0.0091,0.0122,0.013,0.0138,0.0181,0.0181,0.0197,0.0213,0.0246,0.0262,0.0255,0.0299,0.0275,0.0337,0.0319,0.033,0.0339,0.0354,0.0348,0.0359,0.0342,0.034,0.0326,0.0303,0.0279,0.0299,0.0265,0.0277,0.0236,0.0217,0.02,0.0168,0.0164,0.0131,0.0128,0.011,0.00978,0.0104,0.00835,0.00669,0.00584,0.00481,0.00452,0.00309,0.00309,0.00269,0.00246,0.00246,0.00183,0.00143]
    Outputs: [0.0016,0.00171,0.0024,0.00212,0.00309,0.00303,0.00669,0.0135,0.0149,0.0129,0.0113,0.00955,0.00612,0.00806,0.0109,0.0138,0.0175,0.0212,0.0159,0.0147,0.0165,0.0225,0.0351,0.0341,0.0297,0.0261,0.026,0.0279,0.0228,0.0262,0.0328,0.0399,0.038,0.0306,0.027,0.0249,0.0264,0.0239,0.024,0.0237,0.0191,0.0182,0.0194,0.017,0.0177,0.0169,0.0182,0.0168,0.0157,0.013,0.0111,0.0115,0.0139,0.0111,0.00846,0.00612,0.0036,0.00337,0.002,0.00223,0.00212,0.00189,0.00143]