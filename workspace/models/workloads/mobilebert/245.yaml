{{include_text('../problem_base.yaml')}}
problem:
  <<<: *problem_base
  instance: {M: 139, C: 139, P: 4}

  name: MobileBertSelfAttention
  dnn_name: mobilebert
  notes: From einsum
  # These histograms symmetric and zero-centered (the centermost bin is the
  # probability of zero). Histograms are normalized to sum to 1.0 and they have
  # 2^N-1 bins for some integer N. Higher N yields higher-fidelity histograms,
  # but also increases runtime & the size of YAML files. Encoding functions will
  # upsample or downsample histograms depending on the bitwidth of the
  # corresponding operands.
  histograms:
    Inputs:  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.87,0.0504,0.019,0.0111,0.00769,0.00555,0.00506,0.00446,0.00322,0.00265,0.0024,0.00214,0.00169,0.00173,0.00137,0.00122,0.00116,0.00108,0.000967,0.00102,0.00098,0.000549,0.000719,0.000523,0.000549,0.000484,0.000353,0.000366,0.000392,0.000418,0.000392,0.000366]
    Weights: [0.0016,0.00189,0.00223,0.00263,0.00235,0.00412,0.00412,0.00372,0.00458,0.00607,0.00613,0.00744,0.00813,0.0105,0.0104,0.0123,0.0128,0.0138,0.0159,0.0188,0.0236,0.0211,0.0239,0.0266,0.0281,0.0279,0.0305,0.0325,0.0327,0.036,0.0357,0.0348,0.0361,0.0376,0.035,0.0363,0.0328,0.0329,0.0269,0.0273,0.0264,0.024,0.0235,0.0203,0.0177,0.0171,0.0137,0.0138,0.0122,0.00899,0.0079,0.00836,0.00636,0.00573,0.00487,0.00441,0.00309,0.00315,0.00229,0.00332,0.00166,0.00189,0.00149]
    Outputs: [0.002,0.00166,0.00194,0.00251,0.00223,0.00308,0.0024,0.00366,0.00406,0.00463,0.00583,0.00714,0.00823,0.00874,0.00914,0.0105,0.0125,0.0134,0.015,0.0136,0.0181,0.0193,0.0219,0.0254,0.0267,0.0299,0.0334,0.0336,0.0335,0.0389,0.0392,0.0391,0.0416,0.0388,0.0389,0.0399,0.038,0.0363,0.0334,0.0308,0.0258,0.0242,0.0221,0.0179,0.0174,0.0141,0.0147,0.0112,0.00977,0.00794,0.008,0.00703,0.00606,0.00451,0.00394,0.004,0.00286,0.002,0.00217,0.002,0.00137,0.0008,0.0012]