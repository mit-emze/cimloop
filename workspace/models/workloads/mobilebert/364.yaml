{{include_text('../problem_base.yaml')}}
problem:
  <<<: *problem_base
  instance: {M: 139, C: 139, P: 4}

  name: MobileBertSelfAttention
  dnn_name: mobilebert
  notes: From einsum
  # These histograms symmetric and zero-centered (the centermost bin is the
  # probability of zero). Histograms are normalized to sum to 1.0 and they have
  # 2^N-1 bins for some integer N. Higher N yields higher-fidelity histograms,
  # but also increases runtime & the size of YAML files. Encoding functions will
  # upsample or downsample histograms depending on the bitwidth of the
  # corresponding operands.
  histograms:
    Inputs:  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.812,0.0858,0.0301,0.0162,0.0105,0.00787,0.0052,0.00444,0.00386,0.00286,0.00261,0.00216,0.00178,0.00178,0.00136,0.00118,0.00114,0.00105,0.000941,0.000954,0.000601,0.00064,0.000706,0.000732,0.000523,0.000588,0.000457,0.000471,0.000418,0.000431,0.000444,0.000248]
    Weights: [0.002,0.002,0.00177,0.00257,0.00331,0.00371,0.00502,0.00457,0.00611,0.00673,0.00651,0.00902,0.0097,0.00987,0.0118,0.0143,0.0163,0.016,0.0188,0.0192,0.0209,0.0259,0.023,0.0277,0.0312,0.0303,0.0342,0.0326,0.0358,0.0376,0.0372,0.0357,0.0345,0.0345,0.0341,0.0298,0.0314,0.0285,0.0271,0.0264,0.0239,0.0216,0.02,0.0181,0.0164,0.0169,0.0142,0.013,0.0111,0.00896,0.00673,0.00656,0.00622,0.00497,0.00491,0.00377,0.00234,0.00245,0.00263,0.00194,0.00211,0.00154,0.00171]
    Outputs: [0.00137,0.00131,0.00131,0.00222,0.00251,0.00296,0.00359,0.00382,0.00518,0.0053,0.00575,0.00684,0.00741,0.00889,0.0112,0.012,0.0117,0.0158,0.019,0.0172,0.0226,0.0213,0.0268,0.0282,0.0324,0.0372,0.0404,0.04,0.037,0.041,0.0369,0.0358,0.034,0.0353,0.0325,0.0313,0.0265,0.0303,0.03,0.0283,0.0248,0.0216,0.0191,0.0182,0.0178,0.0141,0.0143,0.0132,0.0098,0.00946,0.00889,0.00689,0.00507,0.00456,0.00399,0.00279,0.00268,0.00142,0.00211,0.00194,0.0012,0.00154,0.00125]